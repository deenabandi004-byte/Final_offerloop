"""
Scout Service v2.0 - Conversational job search assistant with URL parsing,
job discovery, and SERP-powered research capabilities.
"""
from __future__ import annotations

import asyncio
import json
import re
import time
import hashlib
import traceback
from dataclasses import dataclass, field, asdict
from typing import Any, Dict, List, Optional, Tuple, Literal
from urllib.parse import urlparse

import httpx
from serpapi import GoogleSearch

from app.config import SERPAPI_KEY, JINA_API_KEY
from app.services.openai_client import get_async_openai_client


# ============================================================================
# CONFIGURATION
# ============================================================================

JINA_READER_URL = "https://r.jina.ai/"
JINA_SEARCH_URL = "https://s.jina.ai/"

# Intent types
IntentType = Literal["URL_PARSE", "JOB_SEARCH", "FIELD_HELP", "RESEARCH", "CONVERSATION"]


# ============================================================================
# DATA CLASSES
# ============================================================================

@dataclass
class SearchFields:
    """Fields that can be auto-populated in the Professional Search form."""
    job_title: Optional[str] = None
    company: Optional[str] = None
    location: Optional[str] = None
    experience_level: Optional[str] = None  # intern, entry, mid, senior, etc.
    
    def to_dict(self) -> Dict[str, Any]:
        return {k: v for k, v in asdict(self).items() if v is not None}
    
    def has_any(self) -> bool:
        return any([self.job_title, self.company, self.location])


@dataclass
class JobListing:
    """A job posting found via search."""
    title: str
    company: str
    location: Optional[str] = None
    url: Optional[str] = None
    snippet: Optional[str] = None
    source: str = "serp"

    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)


@dataclass
class JobFitAnalysis:
    """Analysis of how well a user fits a job posting."""
    overall_score: int  # 0-100
    strengths: List[str]  # What matches well
    gaps: List[str]  # What's missing
    angles: List[str]  # How to position themselves
    experience_match: str  # "strong", "moderate", "stretch"
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)
    
    def format_message(self) -> str:
        """Format analysis for chat display."""
        parts = ["\nðŸŽ¯ **Fit Analysis** (based on your resume):"]
        
        if self.strengths:
            for strength in self.strengths[:3]:
                parts.append(f"âœ… {strength}")
        
        if self.gaps:
            for gap in self.gaps[:2]:
                parts.append(f"âš ï¸ {gap}")
        
        if self.angles:
            parts.append(f"ðŸ’¡ **Angle:** {self.angles[0]}")
        
        return "\n".join(parts)


@dataclass
class DetailedJobFitAnalysis:
    """Comprehensive job fit analysis for a single job."""
    score: int  # 0-100
    match_level: str  # "strong", "good", "moderate", "stretch"
    strengths: List[Dict[str, str]]  # [{"point": "...", "evidence": "..."}]
    gaps: List[Dict[str, str]]  # [{"gap": "...", "mitigation": "..."}]
    pitch: str  # 2-3 sentence positioning statement
    talking_points: List[str]  # For networking/interviews
    keywords_to_use: List[str]  # Resume/cover letter keywords
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)


@dataclass
class ScoutResponse:
    """Response returned to the frontend."""
    status: str  # "ok", "needs_input", "error"
    message: str  # Conversational response to display
    fields: Optional[SearchFields] = None  # Fields to auto-populate
    job_listings: List[JobListing] = field(default_factory=list)  # Job results
    intent: Optional[str] = None  # What Scout understood
    context: Dict[str, Any] = field(default_factory=dict)  # Session context
    fit_analysis: Optional[JobFitAnalysis] = None  # Job fit analysis
    
    def to_dict(self) -> Dict[str, Any]:
        result = {
            "status": self.status,
            "message": self.message,
            "intent": self.intent,
            "context": self.context,
        }
        if self.fields and self.fields.has_any():
            result["fields"] = self.fields.to_dict()
        if self.job_listings:
            result["job_listings"] = [j.to_dict() for j in self.job_listings]
        if self.fit_analysis:
            result["fit_analysis"] = self.fit_analysis.to_dict()
        return result


# ============================================================================
# CACHING
# ============================================================================

class TTLCache:
    """Simple in-memory TTL cache."""
    
    def __init__(self, default_ttl: int = 3600):  # 1 hour default
        self._store: Dict[str, Tuple[float, Any]] = {}
        self._default_ttl = default_ttl

    def get(self, key: str) -> Optional[Any]:
        if key not in self._store:
            return None
        expires_at, value = self._store[key]
        if expires_at < time.time():
            self._store.pop(key, None)
            return None
        return value

    def set(self, key: str, value: Any, ttl: Optional[int] = None) -> None:
        lifetime = ttl if ttl is not None else self._default_ttl
        self._store[key] = (time.time() + lifetime, value)

    def make_key(self, *args) -> str:
        return hashlib.md5(":".join(str(a) for a in args).encode()).hexdigest()


# ============================================================================
# SCOUT SERVICE
# ============================================================================

class ScoutService:
    """Main Scout service orchestrating all functionality."""

    DEFAULT_MODEL = "gpt-4o-mini"
    
    def __init__(self):
        self._cache = TTLCache()
        self._openai = get_async_openai_client()
    
    async def _get_http_client(self) -> httpx.AsyncClient:
        """Create a new HTTP client for each request to avoid event loop issues."""
        return httpx.AsyncClient(timeout=30.0)
    
    # ========================================================================
    # MAIN ENTRY POINT
    # ========================================================================

    async def handle_chat(
        self,
        *,
        message: str,
        context: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """
        Main entry point for Scout chat interactions.
        
        Args:
            message: User's message (can be URL, question, or natural language)
            context: Session context from previous messages
        
        Returns:
            ScoutResponse as dictionary
        """
        context = context or {}
        message = (message or "").strip()
        
        if not message:
            return ScoutResponse(
                status="needs_input",
                message="Hi! I'm Scout ðŸ• I can help you find the right professionals to network with. You can:\n\n"
                        "â€¢ Paste a job posting URL and I'll extract the details\n"
                        "â€¢ Tell me what kind of roles you're looking for (e.g., 'data analyst jobs in NYC')\n"
                        "â€¢ Ask me about companies or roles\n\n"
                        "What would you like to do?",
            context=context,
            ).to_dict()
        
        # Classify intent
        intent, extracted = await self._classify_intent(message, context)
        print(f"[Scout] Intent: {intent}, Extracted: {extracted}")
        
        # Route to appropriate handler
        try:
            if intent == "URL_PARSE":
                response = await self._handle_url_parse(extracted.get("url", message), context)
            elif intent == "JOB_SEARCH":
                response = await self._handle_job_search(message, extracted, context)
            elif intent == "FIELD_HELP":
                response = await self._handle_field_help(message, extracted, context)
            elif intent == "RESEARCH":
                response = await self._handle_research(message, extracted, context)
            else:  # CONVERSATION
                response = await self._handle_conversation(message, context)
            
            response.intent = intent
            return response.to_dict()
            
        except Exception as e:
            print(f"[Scout] Error handling message: {e}")
            return ScoutResponse(
                status="error",
                message="I ran into an issue processing that. Could you try rephrasing or paste the job description text directly?",
                        context=context,
        ).to_dict()

    # ========================================================================
    # INTENT CLASSIFICATION
    # ========================================================================

    async def _classify_intent(
        self,
        message: str,
        context: Dict[str, Any]
    ) -> Tuple[IntentType, Dict[str, Any]]:
        """
        Classify user intent using regex patterns first, then LLM if needed.
        Returns (intent_type, extracted_entities).
        """
        extracted: Dict[str, Any] = {}
        
        # Pattern 1: URL detection (fast path)
        url_pattern = r'https?://[^\s<>"{}|\\^`\[\]]+'
        urls = re.findall(url_pattern, message)
        if urls:
            extracted["url"] = urls[0]
            return "URL_PARSE", extracted
        
        # Pattern 2: Job search patterns - improved to catch more variations
        job_search_patterns = [
            r'\b(find|search|look for|looking for|show me|get me|can you find)\b.*\b(jobs?|roles?|positions?|openings?|postings?)\b',
            r'\b(jobs?|roles?|positions?|openings?|postings?)\b.*\b(in|at|near)\b',
            r'\b(hiring|openings?|postings?)\b.*\b(for|at|in)\b',
            r'\bwho.*(is hiring|are hiring)\b',
            r'\b(data|software|product|marketing|sales|finance|engineering|engineer|analyst|scientist|manager|designer|developer)\b.*\b(jobs?|roles?|positions?|postings?)\b.*\b(in|at|near)\b',
            r'\b(find|search|look for)\b.*\b(postings?|openings?)\b.*\b(in|at|near)\b',
            # Catch "find [role] postings in [location]" pattern
            r'\b(find|search|look for|show me)\b.*\b(postings?|openings?|jobs?)\b',
        ]
        for pattern in job_search_patterns:
            if re.search(pattern, message, re.IGNORECASE):
                # Extract location if mentioned (do this first)
                location_match = re.search(
                    r'\b(?:in|at|near)\s+([A-Z][A-Za-z\s,]+?)(?:\s*$|\s+(?:for|as|with|postings?|openings?|jobs?))',
                    message, re.IGNORECASE
                )
                if location_match:
                    extracted["location"] = location_match.group(1).strip()
                
                # Extract job title/role - improved patterns
                # Pattern 1: "find [job title] in [location]" or "find [job title] jobs"
                role_match = re.search(
                    r'\b(find|search|look for|looking for|show me|get me|can you find)\s+(.+?)\s+(?:in|at|near|jobs?|postings?|openings?|roles?|positions?)',
                    message, re.IGNORECASE
                )
                if role_match:
                    potential_title = role_match.group(2).strip()
                    # Remove location if it was captured in the title
                    if extracted.get("location"):
                        potential_title = re.sub(
                            rf'\b(?:in|at|near)\s+{re.escape(extracted["location"])}\b',
                            '',
                            potential_title,
                            flags=re.IGNORECASE
                        ).strip()
                    # Clean up common action words
                    potential_title = re.sub(
                        r'^\s*(me|you|for|a|an|some)\s+',
                        '',
                        potential_title,
                        flags=re.IGNORECASE
                    ).strip()
                    if potential_title and len(potential_title) > 3:
                        extracted["job_title"] = potential_title
                
                # Pattern 2: "[job title] jobs/internships/positions in [location]"
                if not extracted.get("job_title"):
                    role_match2 = re.search(
                        r'^(.+?)\s+(?:jobs?|internships?|roles?|positions?|postings?|openings?)\s+(?:in|at|near)',
                        message, re.IGNORECASE
                    )
                    if role_match2:
                        potential_title = role_match2.group(1).strip()
                        # Remove action words at the start
                        potential_title = re.sub(
                            r'^\s*(find|search|look for|looking for|show me|get me|can you find|me|you|for)\s+',
                            '',
                            potential_title,
                            flags=re.IGNORECASE
                        ).strip()
                        if potential_title and len(potential_title) > 3:
                            extracted["job_title"] = potential_title
                
                # Pattern 3: Extract everything before "in/at/near" if location exists
                if not extracted.get("job_title") and extracted.get("location"):
                    # Split on location indicator and take the part before
                    parts = re.split(r'\b(?:in|at|near)\s+', message, flags=re.IGNORECASE, maxsplit=1)
                    if len(parts) > 1:
                        before_location = parts[0].strip()
                        # Remove action words
                        before_location = re.sub(
                            r'\b(find|search|look for|looking for|show me|get me|can you find|me|you|for)\s+',
                            '',
                            before_location,
                            flags=re.IGNORECASE
                        ).strip()
                        # Remove trailing "jobs/internships/etc" words
                        before_location = re.sub(
                            r'\s+(?:jobs?|internships?|roles?|positions?|postings?|openings?)\s*$',
                            '',
                            before_location,
                            flags=re.IGNORECASE
                        ).strip()
                        if before_location and len(before_location) > 3:
                            extracted["job_title"] = before_location
                
                return "JOB_SEARCH", extracted
        
        # Pattern 3: Field help patterns
        field_help_patterns = [
            r'\b(what|which)\b.*\b(title|job title|role)\b.*\b(should|would|to use)\b',
            r'\b(help|assist)\b.*\b(fill|input|enter)\b',
            r'\bhow (do|should) i (search|find|look)\b',
            r'\bwhat.*(put|enter|type|input)\b',
        ]
        for pattern in field_help_patterns:
            if re.search(pattern, message, re.IGNORECASE):
                return "FIELD_HELP", extracted
        
        # Pattern 4: Research patterns (questions about companies/roles)
        research_patterns = [
            r'\b(what|how|tell me about|describe)\b.*\b(interview|culture|salary|compensation|benefits)\b',
            r'\bwhat.*(like|about)\b.*\b(work|working)\b.*\bat\b',
            r'\b(interview process|hiring process)\b',
            r'\bhow (hard|difficult|easy)\b.*\b(get|land)\b.*\b(job|role|position)\b',
        ]
        for pattern in research_patterns:
            if re.search(pattern, message, re.IGNORECASE):
                # Extract company if mentioned
                company_match = re.search(r'\bat\s+([A-Z][A-Za-z0-9\s&]+)', message)
                if company_match:
                    extracted["company"] = company_match.group(1).strip()
                return "RESEARCH", extracted
        
        # Fall back to LLM classification for ambiguous cases
        # But first, check if it looks like a job search with a quick heuristic
        if any(word in message.lower() for word in ['find', 'search', 'look for', 'postings', 'openings', 'jobs']) and \
           any(word in message.lower() for word in ['in', 'at', 'near']):
            # Likely a job search - extract what we can
            location_match = re.search(
                r'\b(?:in|at|near)\s+([A-Za-z\s,]+?)(?:\s*$|\s+(?:for|as|with))',
                message, re.IGNORECASE
            )
            if location_match:
                extracted["location"] = location_match.group(1).strip()
            # Try to extract role
            role_match = re.search(
                r'\b(find|search|look for|show me)\s+(.+?)\s+(?:postings?|openings?|jobs?)\s+(?:in|at|near)',
                message, re.IGNORECASE
            )
            if role_match:
                extracted["job_title"] = role_match.group(2).strip()
            return "JOB_SEARCH", extracted
        
        # Fall back to LLM classification for ambiguous cases
        return await self._llm_classify_intent(message, context)
    
    async def _llm_classify_intent(
        self, 
        message: str, 
        context: Dict[str, Any]
    ) -> Tuple[IntentType, Dict[str, Any]]:
        """Use LLM to classify intent when regex patterns don't match."""
        if not self._openai:
            print("[Scout] OpenAI client not available for classification")
            return "CONVERSATION", {}
        
        try:
            prompt = f"""Classify this user message for a job search assistant. Return JSON only.

Message: "{message}"

Recent context: {json.dumps(context.get('recent_topics', []))}

Classify as one of:
- URL_PARSE: User shared a URL to a job posting
- JOB_SEARCH: User wants to find job listings (e.g., "data analyst jobs in SF")
- FIELD_HELP: User needs help with what to enter in search fields
- RESEARCH: User asking about a company, role, interview process, etc.
- CONVERSATION: General chat, follow-up, or unclear intent

Also extract any entities mentioned:
- job_title: specific role mentioned
- company: company name mentioned  
- location: city/location mentioned
- experience_level: intern, entry, mid, senior, etc.

Return format:
{{"intent": "INTENT_TYPE", "entities": {{"job_title": null, "company": null, "location": null, "experience_level": null}}}}
"""
            
            completion = await asyncio.wait_for(
                self._openai.chat.completions.create(
                    model=self.DEFAULT_MODEL,
                    messages=[
                        {"role": "system", "content": "You classify user intents. Return only valid JSON."},
                        {"role": "user", "content": prompt},
                    ],
                    temperature=0,
                    max_tokens=150,
                    response_format={"type": "json_object"},
                ),
                timeout=10.0  # Increased from 5s to handle slower API responses
            )
            
            result = json.loads(completion.choices[0].message.content)
            intent = result.get("intent", "CONVERSATION")
            entities = result.get("entities", {})
            # Filter out null values
            entities = {k: v for k, v in entities.items() if v}
            
            return intent, entities
            
        except asyncio.TimeoutError:
            print("[Scout] LLM classification timed out - using heuristic fallback")
            # Improved heuristic fallback: try harder to extract intent
            extracted: Dict[str, Any] = {}
            
            # Check for job search patterns more thoroughly
            job_keywords = ['find', 'search', 'look for', 'looking for', 'show me', 'want', 'need', 'internships', 'internship', 'postings', 'openings', 'jobs', 'positions', 'roles']
            location_keywords = ['in', 'at', 'near', 'los angeles', 'san francisco', 'new york', 'nyc', 'sf', 'la']
            has_job_keyword = any(word in message.lower() for word in job_keywords)
            has_location_keyword = any(word in message.lower() for word in location_keywords)
            
            if has_job_keyword:
                # Try to extract location
                location_match = re.search(
                    r'\b(?:in|at|near)\s+([A-Z][A-Za-z\s,]+?)(?:\s*$|\s+(?:for|as|with|postings?|openings?|jobs?))',
                    message, re.IGNORECASE
                )
                if location_match:
                    extracted["location"] = location_match.group(1).strip()
                
                # Try to extract job title/role - multiple patterns
                role_patterns = [
                    r'\b(find|search|look for|looking for|show me|want|need|can you find)\s+(.+?)\s+(?:in|at|near|jobs?|internships?|postings?|openings?)',
                    r'(.+?)\s+(?:jobs?|internships?|positions?|roles?|postings?|openings?)\s+(?:in|at|near)',
                ]
                
                for pattern in role_patterns:
                    role_match = re.search(pattern, message, re.IGNORECASE)
                    if role_match:
                        potential_title = role_match.group(1).strip()
                        # Clean up action words
                        potential_title = re.sub(
                            r'^\s*(find|search|look for|looking for|show me|want|need|can you find|me|i\'m|i am|for|a|an)\s+',
                            '',
                            potential_title,
                            flags=re.IGNORECASE
                        ).strip()
                        
                        # Remove location if captured
                        if extracted.get("location"):
                            potential_title = re.sub(
                                rf'\b(?:in|at|near)\s+{re.escape(extracted["location"])}\b',
                                '',
                                potential_title,
                                flags=re.IGNORECASE
                            ).strip()
                        
                        if potential_title and len(potential_title) > 2:
                            extracted["job_title"] = potential_title
                            break
                
                if extracted.get("job_title") or extracted.get("location"):
                    return "JOB_SEARCH", extracted
            
            # If we have location but no job title, still treat as job search
            if has_location_keyword:
                location_match = re.search(
                    r'\b(?:in|at|near)\s+([A-Z][A-Za-z\s,]+?)(?:\s*$|\s+(?:for|as|with))',
                    message, re.IGNORECASE
                )
                if location_match:
                    extracted["location"] = location_match.group(1).strip()
                    return "JOB_SEARCH", extracted
            
            return "CONVERSATION", extracted
        except json.JSONDecodeError as e:
            print(f"[Scout] LLM classification JSON decode error: {e}")
            return "CONVERSATION", {}
        except Exception as e:
            print(f"[Scout] LLM classification failed: {e}")
            print(f"[Scout] Traceback: {traceback.format_exc()}")
            return "CONVERSATION", {}
    
    # ========================================================================
    # URL PARSING (Jina Reader)
    # ========================================================================
    
    async def _handle_url_parse(
        self, 
        url: str, 
        context: Dict[str, Any]
    ) -> ScoutResponse:
        """Parse a job posting URL using Jina Reader and extract fields."""
        
        # Check cache first
        cache_key = self._cache.make_key("url", url)
        cached = self._cache.get(cache_key)
        if cached:
            return cached
        
        # Fetch page content via Jina Reader
        content = await self._fetch_url_content(url)
        
        if not content:
            # Fallback: Try SERP search for the URL
            return await self._handle_url_fallback(url, context)
        
        # Extract job details using LLM
        fields, summary = await self._extract_job_details_from_content(content, url)
        
        if not fields.has_any():
            return ScoutResponse(
                status="needs_input",
                message="I found the page but couldn't extract job details. Could you paste the job title and company name directly?",
                context=self._update_context(context, url=url),
            )
        
        # Analyze job fit if resume available
        user_resume = context.get("user_resume")
        fit_analysis = None
        
        if user_resume and fields.has_any():
            fit_analysis = await self._analyze_job_fit(
                job_content=content,
                fields=fields,
                user_resume=user_resume,
            )
        
        # Build response message
        message_parts = ["ðŸ“‹ **Got it!** I found these details from the job posting:\n"]
        if fields.job_title:
            message_parts.append(f"â€¢ **Job Title:** {fields.job_title}")
        if fields.company:
            message_parts.append(f"â€¢ **Company:** {fields.company}")
        if fields.location:
            message_parts.append(f"â€¢ **Location:** {fields.location}")
        if fields.experience_level:
            message_parts.append(f"â€¢ **Level:** {fields.experience_level}")
        
        # Add fit analysis if available
        if fit_analysis:
            message_parts.append(fit_analysis.format_message())
        
        message_parts.append("\nâœ¨ I've filled these into your search (optimized for better results). Click **Find Contacts** to discover professionals in this role!")
        
        if summary:
            message_parts.append(f"\n\nðŸ’¡ **About this role:** {summary}")
        
        response = ScoutResponse(
            status="ok",
            message="\n".join(message_parts),
            fields=fields,
            fit_analysis=fit_analysis,
            context=self._update_context(context, url=url, fields=fields),
        )
        
        self._cache.set(cache_key, response)
        return response
    
    async def _fetch_url_content(self, url: str) -> Optional[str]:
        """Fetch URL content using Jina Reader API."""
        client = None
        try:
            client = await self._get_http_client()
            jina_url = f"{JINA_READER_URL}{url}"
            
            headers = {}
            if JINA_API_KEY:
                headers["Authorization"] = f"Bearer {JINA_API_KEY}"
            
            # Use shorter timeout to match the outer wait_for timeout (5s)
            # This prevents long waits and reduces chance of cancellation issues
            response = await client.get(jina_url, headers=headers, timeout=4.5)
            
            if response.status_code == 200:
                content = response.text
                # Limit content length to avoid token limits
                if len(content) > 15000:
                    content = content[:15000] + "\n... [truncated]"
                return content
            else:
                print(f"[Scout] Jina Reader returned {response.status_code} for {url}")
                return None
                
        except asyncio.TimeoutError:
            print(f"[Scout] Jina Reader timeout for {url}")
            return None
        except asyncio.CancelledError:
            print(f"[Scout] Fetch cancelled for {url}")
            return None
        except httpx.TimeoutException:
            print(f"[Scout] HTTP timeout for {url}")
            return None
        except httpx.RequestError as e:
            print(f"[Scout] HTTP request error for {url}: {type(e).__name__}: {e}")
            return None
        except RuntimeError as e:
            if "Event loop is closed" in str(e):
                print(f"[Scout] Event loop closed error for {url} - this is usually harmless")
            else:
                print(f"[Scout] Runtime error fetching URL via Jina: {e}")
            return None
        except Exception as e:
            print(f"[Scout] Error fetching URL via Jina: {type(e).__name__}: {e}")
            # Don't print full traceback for expected errors (timeouts, cancellations)
            if not isinstance(e, (asyncio.TimeoutError, asyncio.CancelledError, httpx.TimeoutException)):
                print(f"[Scout] Traceback: {traceback.format_exc()}")
            return None
        finally:
            # Always close the client to avoid resource leaks
            if client:
                try:
                    await client.aclose()
                except Exception:
                    pass  # Ignore errors when closing

    async def _extract_job_details_from_content(
        self,
        content: str,
        url: str
    ) -> Tuple[SearchFields, Optional[str]]:
        """Extract job details from page content using LLM."""
        if not self._openai:
            print("[Scout] OpenAI client not available for job extraction")
            return SearchFields(), None
        
        try:
            # Infer company from URL if possible
            domain_hint = self._extract_company_from_url(url)
            
            prompt = f"""Extract job posting details from this content. Return JSON only.

URL: {url}
Domain hint: {domain_hint or "unknown"}

Content:
{content[:8000]}

Extract:
- job_title: A simplified, searchable job title (e.g., "Software Engineer", "Data Analyst Intern"). 
  Remove team names, project names, and extra qualifiers. Keep only the core role.
  Example: "AI Research Scientist, Text Data Research - MSL FAIR" -> "AI Research Scientist"
- company: Company name
- location: City, State or "Remote" if mentioned
- experience_level: One of: intern, entry, mid, senior, lead, manager, director, or null
- summary: 1-2 sentence summary of the role (for context)

Return format:
{{"job_title": "...", "company": "...", "location": "...", "experience_level": "...", "summary": "..."}}

If a field cannot be determined, use null.
"""
            
            completion = await asyncio.wait_for(
                self._openai.chat.completions.create(
                    model=self.DEFAULT_MODEL,
                    messages=[
                        {"role": "system", "content": "You extract structured job posting data. Return only valid JSON."},
                        {"role": "user", "content": prompt},
                    ],
                    temperature=0,
                    max_tokens=300,
                    response_format={"type": "json_object"},
                ),
                timeout=15.0  # Increased from 10s to handle complex pages
            )
            
            result = json.loads(completion.choices[0].message.content)
            
            # Extract raw values
            raw_title = result.get("job_title")
            raw_company = result.get("company") or domain_hint
            raw_location = result.get("location")
            
            # Apply normalization
            fields = SearchFields(
                job_title=self._simplify_job_title(raw_title) if raw_title else None,
                company=self._normalize_company(raw_company) if raw_company else None,
                location=self._normalize_location(raw_location) if raw_location else None,
                experience_level=result.get("experience_level"),
            )
            summary = result.get("summary")
            
            return fields, summary
            
        except asyncio.TimeoutError:
            print("[Scout] Job extraction timed out (15s limit)")
            return SearchFields(), None
        except json.JSONDecodeError as e:
            print(f"[Scout] Job extraction JSON decode error: {e}")
            return SearchFields(), None
        except Exception as e:
            print(f"[Scout] Error extracting job details: {type(e).__name__}: {e}")
            print(f"[Scout] Traceback: {traceback.format_exc()}")
            return SearchFields(), None
    
    def _extract_company_from_url(self, url: str) -> Optional[str]:
        """Try to extract company name from URL domain."""
        try:
            parsed = urlparse(url)
            domain = parsed.netloc.lower()
            
            # Common ATS patterns
            ats_patterns = {
                "greenhouse.io": lambda d: d.split(".greenhouse.io")[0].replace("-", " ").title(),
                "lever.co": lambda d: d.split(".lever.co")[0].replace("-", " ").title(),
                "jobs.lever.co": lambda d: d.replace("jobs.lever.co/", "").split("/")[0].replace("-", " ").title(),
                "myworkdayjobs.com": lambda d: d.split(".myworkdayjobs.com")[0].replace("-", " ").title(),
                "smartrecruiters.com": lambda d: None,  # Company in path
                "linkedin.com": lambda d: None,  # Can't extract
            }
            
            for pattern, extractor in ats_patterns.items():
                if pattern in domain:
                    return extractor(domain)
            
            # Try to get company from subdomain or path
            if "careers" in domain or "jobs" in domain:
                parts = domain.replace("careers.", "").replace("jobs.", "").split(".")
                if parts[0] not in ["www", "apply"]:
                    return parts[0].replace("-", " ").title()
            
            return None
            
        except Exception:
            return None
    
    async def _analyze_job_fit(
        self,
        job_content: str,  # Raw job description or extracted details
        fields: SearchFields,  # Extracted job fields
        user_resume: Dict[str, Any],  # User's resume data
    ) -> Optional[JobFitAnalysis]:
        """Analyze how well the user fits a job posting."""
        
        if not user_resume or not self._openai:
            return None
        
        try:
            prompt = f"""Analyze how well this candidate fits the job. Return JSON only.

JOB DETAILS:
Title: {fields.job_title or 'Unknown'}
Company: {fields.company or 'Unknown'}
Location: {fields.location or 'Unknown'}
Level: {fields.experience_level or 'Unknown'}

JOB DESCRIPTION (if available):
{job_content[:3000] if job_content else 'Not available'}

CANDIDATE RESUME:
{json.dumps(user_resume, indent=2)[:4000]}

Analyze and return:
{{
    "overall_score": <0-100 fit score>,
    "strengths": ["strength 1", "strength 2", "strength 3"],
    "gaps": ["gap 1", "gap 2"],
    "angles": ["positioning suggestion"],
    "experience_match": "strong" | "moderate" | "stretch"
}}

Guidelines:
- strengths: Skills, experiences, or background that match well (be specific)
- gaps: Requirements they may not fully meet (be honest but constructive)
- angles: How they could position their experience to stand out
- experience_match: "strong" if experience level matches, "stretch" if reaching up, "moderate" if slight mismatch

Be concise. Each strength/gap should be under 15 words.
"""
            
            completion = await asyncio.wait_for(
                self._openai.chat.completions.create(
                    model=self.DEFAULT_MODEL,
                    messages=[
                        {"role": "system", "content": "You are a career advisor analyzing job fit. Be honest, specific, and helpful. Return only valid JSON."},
                        {"role": "user", "content": prompt},
                    ],
                    temperature=0.3,
                    max_tokens=400,
                    response_format={"type": "json_object"},
                ),
                timeout=10.0
            )
            
            result = json.loads(completion.choices[0].message.content)
            
            return JobFitAnalysis(
                overall_score=result.get("overall_score", 50),
                strengths=result.get("strengths", []),
                gaps=result.get("gaps", []),
                angles=result.get("angles", []),
                experience_match=result.get("experience_match", "moderate"),
            )
            
        except Exception as e:
            print(f"[Scout] Job fit analysis failed: {e}")
            return None
    
    async def analyze_job_fit(
        self,
        job: Dict[str, Any],
        user_resume: Dict[str, Any],
    ) -> Dict[str, Any]:
        """
        Deep analysis of user fit for a specific job.
        Called on-demand when user clicks "Analyze Fit".
        """
        
        if not self._openai:
            return {"status": "error", "message": "Analysis unavailable"}
        
        # If job has URL, try to fetch full description for better analysis
        # Use a shorter timeout for URL fetch to avoid blocking analysis
        job_content = job.get("snippet", "")
        if job.get("url"):
            try:
                full_content = await asyncio.wait_for(
                    self._fetch_url_content(job["url"]),
                    timeout=5.0  # Quick timeout for URL fetch
                )
                if full_content:
                    job_content = full_content[:4000]  # Reduced from 5000 to speed up analysis
            except (asyncio.TimeoutError, asyncio.CancelledError, Exception) as e:
                print(f"[Scout] URL fetch failed for {job.get('url')}: {type(e).__name__} - using snippet")
                # Continue with snippet if URL fetch fails - analysis can proceed with snippet
                pass
        
        try:
            prompt = f"""You are a career coach analyzing job fit. Provide detailed, actionable analysis.

## JOB POSTING
Title: {job.get('title', 'Unknown')}
Company: {job.get('company', 'Unknown')}
Location: {job.get('location', 'Unknown')}

Description:
{job_content if job_content else 'No detailed description available'}

## CANDIDATE RESUME
{json.dumps(user_resume, indent=2)[:4000]}

## INSTRUCTIONS
Analyze the fit and return JSON:

{{
    "score": <0-100>,
    "match_level": "strong" | "good" | "moderate" | "stretch",
    "strengths": [
        {{
            "point": "What matches well (specific skill/experience)",
            "evidence": "Concrete proof from their resume"
        }}
    ],
    "gaps": [
        {{
            "gap": "What's missing or weak",
            "mitigation": "How to address this in application/interview"
        }}
    ],
    "pitch": "A 2-3 sentence positioning statement they could use to introduce themselves for this role. Make it specific and compelling.",
    "talking_points": [
        "Specific point to bring up in networking/interview",
        "Another specific talking point"
    ],
    "keywords_to_use": ["keyword1", "keyword2", "keyword3"]
}}

## GUIDELINES
- score: 80+ = strong, 60-79 = good, 40-59 = moderate, <40 = stretch
- strengths: 2-4 items, be SPECIFIC with evidence from resume
- gaps: 1-3 items, always include mitigation strategy
- pitch: Write in first person, something they could actually say
- talking_points: 3-5 specific, actionable points
- keywords_to_use: Terms from job posting to include in their materials

Be honest but constructive. Focus on actionable insights.
"""
            
            completion = await asyncio.wait_for(
                self._openai.chat.completions.create(
                    model=self.DEFAULT_MODEL,
                    messages=[
                        {
                            "role": "system", 
                            "content": "You are an expert career coach. Provide specific, actionable job fit analysis. Return only valid JSON."
                        },
                        {"role": "user", "content": prompt},
                    ],
                    temperature=0.4,
                    max_tokens=800,
                    response_format={"type": "json_object"},
                ),
                timeout=25.0  # Increased from 15s to handle slower API responses
            )
            
            result = json.loads(completion.choices[0].message.content)
            
            return {
                "status": "ok",
                "analysis": result,
            }
            
        except asyncio.TimeoutError:
            return {"status": "error", "message": "Analysis timed out"}
        except Exception as e:
            print(f"[Scout] Job fit analysis failed: {e}")
            import traceback
            print(f"[Scout] Traceback: {traceback.format_exc()}")
            return {"status": "error", "message": "Analysis failed"}
    
    async def _handle_url_fallback(
        self, 
        url: str, 
        context: Dict[str, Any]
    ) -> ScoutResponse:
        """Fallback when URL fetching fails - try SERP or ask user."""
        # Try to extract company from URL
        company = self._extract_company_from_url(url)
        
        if company:
            # Search for jobs at this company
            return await self._handle_job_search(
                f"jobs at {company}",
                {"company": company},
                context
            )
        
        return ScoutResponse(
            status="needs_input",
            message="I couldn't access that URL directly. Could you try one of these:\n\n"
                    "1. **Paste the job description text** directly\n"
                    "2. **Tell me the job title and company** (e.g., 'Software Engineer at Google')\n"
                    "3. **Share a different URL** to the same posting",
            context=self._update_context(context, failed_url=url),
        )
    
    # ========================================================================
    # JOB SEARCH (SERP)
    # ========================================================================
    
    async def _handle_job_search(
        self, 
        message: str,
        extracted: Dict[str, Any],
        context: Dict[str, Any]
    ) -> ScoutResponse:
        """Handle job search queries using SERP API."""
        
        # Build search query
        query = await self._build_job_search_query(message, extracted, context)
        print(f"[Scout] Job search query: {query}")
        
        # Search for jobs
        jobs = await self._search_jobs(query)
        
        if not jobs:
            # Fallback: suggest common job titles
            return await self._handle_no_jobs_found(message, extracted, context)
        
        # Extract fields from first few results
        fields = self._aggregate_fields_from_jobs(jobs, extracted)
        
        # Simple, fast response - no auto-analysis
        location_display = fields.location if fields.location else extracted.get("location", "your area")
        message_text = f"ðŸ” **Found {len(jobs)} positions in {location_display}**\n\n"
        
        user_resume = context.get("user_resume")
        if user_resume:
            message_text += "ðŸ’¡ Click **Analyze Fit** on any job to see how well you match!"
        else:
            message_text += "âœ¨ Click any job listing to use it for your search."
        
        # Add note about optimization if fields were normalized
        if fields.has_any():
            message_text += "\n\nâœ¨ Search fields have been optimized for better contact matching."
        
        return ScoutResponse(
            status="ok",
            message=message_text,
            fields=fields,
            job_listings=jobs[:10],
            context=self._update_context(context, search_query=query, fields=fields),
        )
    
    async def _build_job_search_query(
        self,
        message: str,
        extracted: Dict[str, Any],
        context: Dict[str, Any]
    ) -> str:
        """Build an optimized search query for job postings."""
        # Start with user's message, clean it up
        query_parts = []
        
        # Add job title/role if extracted
        if extracted.get("job_title"):
            query_parts.append(extracted["job_title"])
        
        # Add location if extracted
        if extracted.get("location"):
            query_parts.append(f"in {extracted['location']}")
        
        # Add company if extracted
        if extracted.get("company"):
            query_parts.append(f"at {extracted['company']}")
        
        # If we have parts, use them; otherwise clean up the message
        if query_parts:
            query = " ".join(query_parts)
            # Only add "jobs" if not already present
            if "job" not in query.lower() and "internship" not in query.lower():
                query += " jobs"
        else:
            # Clean message for search - preserve the actual job title
            query = re.sub(r'\b(find|search|look for|looking for|show me|get me|can you find|me)\s+', '', message, flags=re.IGNORECASE)
            query = query.strip()
            # Don't add "jobs" if "internships" or similar is already there
            if "job" not in query.lower() and "internship" not in query.lower() and "position" not in query.lower():
                query += " jobs"
        
        return query
    
    async def _search_jobs(self, query: str) -> List[JobListing]:
        """Search for job postings using SERP API."""
        try:
            # Check cache
            cache_key = self._cache.make_key("jobs", query)
            cached = self._cache.get(cache_key)
            if cached:
                return cached
            
            # Use Google Jobs engine for better results
            search = GoogleSearch({
            "engine": "google_jobs",
                "q": query,
                "api_key": SERPAPI_KEY,
                "num": 10,
            "hl": "en",
                "gl": "us",
            })
            
            # Run in thread pool to not block
            loop = asyncio.get_event_loop()
            results = await loop.run_in_executor(None, search.get_dict)
            
            jobs = []
            
            # Parse jobs_results from Google Jobs
            for result in results.get("jobs_results", [])[:10]:
                title = result.get("title", "").strip()
                company = result.get("company_name", "").strip()
                location = result.get("location", "").strip()
                description = result.get("description", "")
                
                # Try multiple possible URL fields from Google Jobs API
                # Google Jobs API often uses apply_options for direct links to actual job postings
                # share_link points to Google search results, not the actual job
                link = None
                
                # Priority 1: Try apply_options first (these are direct links to actual job postings)
                # LinkedIn is usually the best source, so prefer it if available
                apply_options = result.get("apply_options", [])
                if isinstance(apply_options, list) and len(apply_options) > 0:
                    # First, try to find LinkedIn link (most reliable)
                    for option in apply_options:
                        if isinstance(option, dict):
                            option_title = (option.get("title") or "").lower()
                            apply_url = (option.get("link") or option.get("url") or "").strip()
                            if apply_url and apply_url.startswith("http"):
                                # Prefer LinkedIn, but take the first valid one if no LinkedIn found
                                if "linkedin" in option_title or "linkedin" in apply_url.lower():
                                    link = apply_url
                                    break
                                elif not link:  # Keep first valid link as fallback
                                    link = apply_url
                    
                    # If we found LinkedIn, use it; otherwise use first valid link
                    # (link is already set above if found)
                
                # Priority 2: Try other direct link fields (skip share_link as it's a Google search URL)
                if not link:
                    link = (
                        result.get("link") or 
                        result.get("apply_link") or 
                        result.get("url") or
                        ""
                    ).strip()
                    if link and link.startswith("http") and "google.com/search" not in link:
                        pass  # Keep it if it's not a Google search URL
                    else:
                        link = None
                
                # Priority 3: Only use share_link as last resort if it's not a Google search URL
                # (Usually share_link is a Google search URL, so we skip it)
                if not link:
                    share_link = result.get("share_link", "").strip()
                    if share_link and share_link.startswith("http") and "google.com/search" not in share_link:
                        link = share_link
                
                # Debug: Log available fields for first result
                if len(jobs) == 0:
                    print(f"[Scout] Debug - First job result fields: {list(result.keys())}")
                    print(f"[Scout] Debug - share_link: {result.get('share_link')}")
                    print(f"[Scout] Debug - apply_options: {result.get('apply_options')}")
                    print(f"[Scout] Debug - Final link: {link}")
                
                # Skip invalid results
                if not title or title.lower() in ["job search", "jobs", "careers", "hiring"]:
                    continue
                if not company or company.lower() in ["unknown", "jobs", "careers"]:
                    continue
                
                # Simplify the title before storing
                simplified_title = self._simplify_job_title(title)
                # Normalize company and location
                normalized_company = self._normalize_company(company) if company else None
                normalized_location = self._normalize_location(location) if location else None
                
                jobs.append(JobListing(
                    title=simplified_title,  # Use simplified title
                    company=normalized_company or company,  # Use normalized if available
                    location=normalized_location or location,  # Use normalized if available
                    url=link,  # Will be None if we couldn't find a valid URL
                    snippet=description[:200] if description else None,
                    source="google_jobs"
                ))
            
            # If no jobs_results, try organic results as fallback
            if not jobs:
                for result in results.get("organic_results", [])[:5]:
                    title = result.get("title", "").strip()
                    snippet = result.get("snippet", "").strip()
                    link = (result.get("link") or result.get("url") or "").strip()
                    
                    # Skip generic job board pages
                    if any(skip in title.lower() for skip in ["job search", "jobs at", "careers at", "hiring"]):
                        continue
                    
                    # Only use if we have a valid URL
                    if not link or not link.startswith("http"):
                        link = None
                    
                    # Try to extract job details
                    job_title, company, location = self._parse_job_from_serp_result(title, snippet, link or "")
                    
                    if job_title and job_title.lower() not in ["job search", "jobs", "careers"]:
                        # Simplify the title before storing
                        simplified_title = self._simplify_job_title(job_title)
                        # Normalize company and location
                        normalized_company = self._normalize_company(company) if company else None
                        normalized_location = self._normalize_location(location) if location else None
                        
                        jobs.append(JobListing(
                            title=simplified_title,  # Use simplified title
                            company=normalized_company or company or "Unknown",
                            location=normalized_location or location,
                            url=link,  # Will be None if invalid
                            snippet=snippet[:200] if snippet else None,
                            source="serp"
                        ))
            
            self._cache.set(cache_key, jobs, ttl=1800)  # Cache for 30 min
            return jobs
            
        except Exception as e:
            print(f"[Scout] SERP search failed: {e}")
            print(f"[Scout] Traceback: {traceback.format_exc()}")
            return []

    def _parse_job_from_serp_result(
        self,
        title: str,
        snippet: str,
        url: str
    ) -> Tuple[Optional[str], Optional[str], Optional[str]]:
        """Parse job title, company, and location from SERP result."""
        job_title = None
        company = None
        location = None
        
        # Skip generic titles
        generic_titles = ["job search", "jobs", "careers", "hiring", "openings"]
        if title.lower() in generic_titles:
            return None, None, None
        
        # Common patterns in job listing titles
        # "Software Engineer - Google" or "Software Engineer at Google"
        patterns = [
            r'^(.+?)\s*[-â€“â€”]\s*(.+?)(?:\s*[-â€“â€”]\s*(.+))?$',  # Title - Company - Location
            r'^(.+?)\s+at\s+(.+?)(?:\s*[-â€“â€”,]\s*(.+))?$',   # Title at Company - Location
            r'^(.+?)\s*\|\s*(.+?)(?:\s*\|\s*(.+))?$',       # Title | Company | Location
        ]
        
        for pattern in patterns:
            match = re.match(pattern, title, re.IGNORECASE)
            if match:
                potential_title = match.group(1).strip()
                potential_company = match.group(2).strip() if match.group(2) else None
                potential_location = match.group(3).strip() if match.lastindex >= 3 and match.group(3) else None
                
                # Validate that we got meaningful data
                if potential_title and potential_title.lower() not in generic_titles:
                    job_title = potential_title
                    if potential_company and potential_company.lower() not in ["jobs", "careers", "hiring"]:
                        company = potential_company
                    if potential_location:
                        location = potential_location
                    break
        
        # If no match, use the whole title as job title (if it's not generic)
        if not job_title and title.lower() not in generic_titles:
            job_title = title
        
        # Try to extract company from snippet if not found
        if not company and snippet:
            # Look for "at Company" or "Company is hiring" patterns
            company_match = re.search(r'\b(at|from|with)\s+([A-Z][A-Za-z0-9\s&]+?)(?:\s|,|\.|$)', snippet, re.IGNORECASE)
            if company_match:
                potential_company = company_match.group(2).strip()
                if potential_company.lower() not in ["jobs", "careers", "hiring", "the", "a", "an"]:
                    company = potential_company
        
        # Try to get company from URL
        if not company:
            company = self._extract_company_from_url(url)
        
        # Extract location from snippet if not found
        if not location and snippet:
            # Look for location patterns like "in City, State" or "City, State"
            location_match = re.search(r'\b(in|at|near)\s+([A-Z][A-Za-z\s,]+?)(?:\s|,|\.|$)', snippet, re.IGNORECASE)
            if location_match:
                potential_location = location_match.group(2).strip()
                # Basic validation - should contain letters and possibly commas
                if len(potential_location) > 2 and any(c.isalpha() for c in potential_location):
                    location = potential_location
        
        return job_title, company, location
    
    def _aggregate_fields_from_jobs(
        self,
        jobs: List[JobListing],
        extracted: Dict[str, Any]
    ) -> SearchFields:
        """Aggregate the most common/relevant fields from job listings."""
        # Use extracted fields as base
        raw_job_title = extracted.get("job_title")
        # Simplify the job title if it's too specific
        job_title = self._simplify_job_title(raw_job_title) if raw_job_title else None
        company = extracted.get("company")
        location = extracted.get("location")
        
        # Filter out invalid jobs
        valid_jobs = [
            j for j in jobs 
            if j.title 
            and j.title.lower() not in ["job search", "jobs", "careers", "hiring", "unknown"]
            and j.company 
            and j.company.lower() not in ["unknown", "jobs", "careers", "hiring"]
        ]
        
        # If not extracted, use most common from results
        if not job_title and valid_jobs:
            # Get the most common job title (not the shortest, but the most frequent)
            # First simplify all titles
            simplified_titles = {}
            for j in valid_jobs:
                simplified = self._simplify_job_title(j.title)
                if simplified:
                    simplified_titles[simplified] = simplified_titles.get(simplified, 0) + 1
            
            if simplified_titles:
                # Get the most common simplified title
                most_common = max(simplified_titles.items(), key=lambda x: x[1])[0]
                job_title = most_common
        
        if not company and valid_jobs:
            companies = [j.company for j in valid_jobs if j.company and j.company != "Unknown"]
            if companies:
                # Get most common company
                company_counts = {}
                for c in companies:
                    company_key = c.strip().lower()
                    company_counts[company_key] = company_counts.get(company_key, 0) + 1
                if company_counts:
                    most_common_company = max(company_counts.items(), key=lambda x: x[1])
                    company = most_common_company[0].title()
        
        if not location and valid_jobs:
            locations = [j.location for j in valid_jobs if j.location]
            if locations:
                # Get most common location
                location_counts = {}
                for loc in locations:
                    loc_key = loc.strip().lower()
                    location_counts[loc_key] = location_counts.get(loc_key, 0) + 1
                if location_counts:
                    most_common_location = max(location_counts.items(), key=lambda x: x[1])
                    location = most_common_location[0].title()
        
        # Apply normalization to aggregated fields
        return SearchFields(
            job_title=self._simplify_job_title(job_title) if job_title else None,
            company=self._normalize_company(company) if company else None,
            location=self._normalize_location(location) if location else None,
        )
    
    async def _handle_no_jobs_found(
        self,
        message: str,
        extracted: Dict[str, Any],
        context: Dict[str, Any]
    ) -> ScoutResponse:
        """Handle case when no jobs are found - suggest alternatives."""
        suggestions = await self._get_title_suggestions(message, extracted)
        
        message_parts = [
            "ðŸ¤” I couldn't find exact matches. Here are some suggestions:\n"
        ]
        
        if suggestions:
            message_parts.append("**Try searching for:**")
            for s in suggestions[:5]:
                message_parts.append(f"â€¢ {s}")
        
        message_parts.append("\nðŸ’¡ **Tips:**")
        message_parts.append("â€¢ Try broader job titles (e.g., 'Analyst' instead of 'Junior Data Analyst')")
        message_parts.append("â€¢ Check the spelling of company names")
        message_parts.append("â€¢ Try a larger city or metro area")
        
        return ScoutResponse(
            status="needs_input",
            message="\n".join(message_parts),
            context=context,
        )
    
    async def _get_title_suggestions(
        self,
        message: str,
        extracted: Dict[str, Any]
    ) -> List[str]:
        """Get alternative job title suggestions."""
        if not self._openai:
            return []
        
        try:
            prompt = f"""The user is looking for: "{message}"
Extracted info: {json.dumps(extracted)}

Suggest 5 alternative, commonly-used job titles they might search for.
Focus on titles that would have many professionals on LinkedIn.

Return as JSON: {{"suggestions": ["title1", "title2", ...]}}
"""
            
            completion = await asyncio.wait_for(
                self._openai.chat.completions.create(
                    model=self.DEFAULT_MODEL,
                    messages=[
                        {"role": "system", "content": "You suggest job titles. Return JSON only."},
                        {"role": "user", "content": prompt},
                    ],
                    temperature=0.7,
                    max_tokens=150,
                    response_format={"type": "json_object"},
                ),
                timeout=5.0
            )
            
            result = json.loads(completion.choices[0].message.content)
            return result.get("suggestions", [])
            
        except Exception as e:
            print(f"[Scout] Error getting suggestions: {e}")
            print(f"[Scout] Traceback: {traceback.format_exc()}")
            return []
    
    # ========================================================================
    # FIELD HELP
    # ========================================================================
    
    async def _handle_field_help(
        self,
        message: str,
        extracted: Dict[str, Any],
        context: Dict[str, Any]
    ) -> ScoutResponse:
        """Help users understand what to enter in search fields."""
        
        if not self._openai:
            return ScoutResponse(
                status="ok",
                message="Here are some tips for filling in the search:\n\n"
                        "â€¢ **Job Title**: Use common titles like 'Software Engineer', 'Product Manager', 'Data Analyst'\n"
                        "â€¢ **Company**: Optional - leave blank to search across all companies\n"
                        "â€¢ **Location**: Use city names like 'San Francisco, CA' or 'New York, NY'\n\n"
                        "What specific role are you interested in? I can help you find the right search terms!",
                context=context,
            )
        
        prompt = f"""The user needs help with job search fields. Their message: "{message}"

Context from conversation: {json.dumps(context.get('recent_topics', []))}

Provide helpful, specific advice about:
1. What job titles to search for (be specific based on their interests)
2. Whether to include company name or leave it broad
3. Best practices for location (city vs metro area)

Keep response concise and actionable. Use bullet points.
If you can infer specific titles they should try, list them.
"""
        
        try:
            completion = await asyncio.wait_for(
                self._openai.chat.completions.create(
                    model=self.DEFAULT_MODEL,
                    messages=[
                        {"role": "system", "content": "You are Scout, a helpful job search assistant. Be friendly and concise."},
                        {"role": "user", "content": prompt},
                    ],
                    temperature=0.7,
                    max_tokens=400,
                ),
                timeout=8.0
            )
            
            response_text = completion.choices[0].message.content
            
            return ScoutResponse(
                status="ok",
                message=response_text,
                context=self._update_context(context, topic="field_help"),
            )
            
        except Exception as e:
            print(f"[Scout] Field help failed: {e}")
            print(f"[Scout] Traceback: {traceback.format_exc()}")
            return ScoutResponse(
                status="ok",
                message="Here are some tips for filling in the search:\n\n"
                        "â€¢ **Job Title**: Use common titles like 'Software Engineer', 'Product Manager', 'Data Analyst'\n"
                        "â€¢ **Company**: Optional - leave blank to search across all companies\n"
                        "â€¢ **Location**: Use city names like 'San Francisco, CA' or 'New York, NY'\n\n"
                        "What specific role are you interested in? I can help you find the right search terms!",
                context=context,
            )
    
    # ========================================================================
    # RESEARCH (Company/Role Info)
    # ========================================================================
    
    async def _handle_research(
        self,
        message: str,
        extracted: Dict[str, Any],
        context: Dict[str, Any]
    ) -> ScoutResponse:
        """Handle research questions about companies, roles, interviews, etc."""
        
        # Build search query for research
        search_query = message
        if extracted.get("company"):
            search_query = f"{extracted['company']} {message}"
        
        # Search for information
        try:
            search = GoogleSearch({
                "q": search_query,
                "api_key": SERPAPI_KEY,
                "num": 5,
            })
            
            loop = asyncio.get_event_loop()
            results = await loop.run_in_executor(None, search.get_dict)
            
            # Collect snippets for context
            snippets = []
            for result in results.get("organic_results", [])[:5]:
                snippet = result.get("snippet", "")
                source = result.get("displayed_link", "")
                if snippet:
                    snippets.append(f"[{source}]: {snippet}")
            
            research_context = "\n".join(snippets)
            
        except Exception as e:
            print(f"[Scout] Research SERP failed: {e}")
            research_context = ""
        
        # Generate response with LLM
        if not self._openai:
            return ScoutResponse(
                status="ok",
                message="I found some information but had trouble summarizing it. Try asking a more specific question, like:\n\n"
                        "â€¢ 'What's the interview process at [Company]?'\n"
                        "â€¢ 'What skills are needed for [Role]?'\n"
                        "â€¢ 'How is the culture at [Company]?'",
                context=context,
            )
        
        try:
            prompt = f"""The user is researching: "{message}"
            
Company mentioned: {extracted.get('company', 'not specified')}
Role mentioned: {extracted.get('job_title', 'not specified')}

Search results for context:
{research_context}

Provide a helpful, informative response. Include:
1. Direct answer to their question
2. Relevant insights from search results
3. A follow-up suggestion for their job search

Keep it concise but informative. Use formatting for readability.
"""
            
            completion = await asyncio.wait_for(
                self._openai.chat.completions.create(
                model=self.DEFAULT_MODEL,
                messages=[
                        {"role": "system", "content": "You are Scout, a knowledgeable job search assistant. Provide helpful research insights."},
                        {"role": "user", "content": prompt},
                    ],
                    temperature=0.7,
                    max_tokens=500,
                ),
                timeout=10.0
            )
            
            response_text = completion.choices[0].message.content
            
            # If we found fields, include them (with normalization)
            fields = None
            if extracted.get("job_title") or extracted.get("company"):
                fields = SearchFields(
                    job_title=self._simplify_job_title(extracted.get("job_title")) if extracted.get("job_title") else None,
                    company=self._normalize_company(extracted.get("company")) if extracted.get("company") else None,
                    location=self._normalize_location(extracted.get("location")) if extracted.get("location") else None,
                )
            
            return ScoutResponse(
                status="ok",
                message=response_text,
                fields=fields,
                context=self._update_context(context, topic="research", company=extracted.get("company")),
            )
            
        except Exception as e:
            print(f"[Scout] Research response failed: {e}")
            print(f"[Scout] Traceback: {traceback.format_exc()}")
            return ScoutResponse(
                status="ok",
                message="I found some information but had trouble summarizing it. Try asking a more specific question, like:\n\n"
                        "â€¢ 'What's the interview process at [Company]?'\n"
                        "â€¢ 'What skills are needed for [Role]?'\n"
                        "â€¢ 'How is the culture at [Company]?'",
                context=context,
            )
    
    # ========================================================================
    # CONVERSATION (General Chat)
    # ========================================================================
    
    async def _handle_conversation(
        self,
        message: str,
        context: Dict[str, Any]
    ) -> ScoutResponse:
        """Handle general conversation and follow-ups."""
        
        # Quick check: if this looks like a job search, handle it as such
        if any(word in message.lower() for word in ['find', 'search', 'look for', 'postings', 'openings', 'jobs']) and \
           any(word in message.lower() for word in ['in', 'at', 'near', 'los angeles', 'san francisco', 'new york', 'nyc', 'sf', 'la']):
            # Extract what we can
            extracted = {}
            location_match = re.search(
                r'\b(?:in|at|near)\s+([A-Za-z\s,]+?)(?:\s*$|\s+(?:for|as|with))',
                message, re.IGNORECASE
            )
            if location_match:
                extracted["location"] = location_match.group(1).strip()
            role_match = re.search(
                r'\b(find|search|look for|show me|can you find)\s+(.+?)\s+(?:postings?|openings?|jobs?)\s+(?:in|at|near)',
                message, re.IGNORECASE
            )
            if role_match:
                extracted["job_title"] = role_match.group(2).strip()
            # Treat as job search
            return await self._handle_job_search(message, extracted, context)
        
        if not self._openai:
            print("[Scout] OpenAI client not available for conversation")
            return ScoutResponse(
                status="ok",
                message="I'm here to help you find professionals to network with! You can:\n\n"
                        "ðŸ”— **Paste a job posting URL** - I'll extract the details\n"
                        "ðŸ” **Describe what you're looking for** - e.g., 'data analyst jobs in NYC'\n"
                        "â“ **Ask me anything** - about companies, roles, or interviews\n\n"
                        "What would you like to do?",
                context=context,
            )
        
        # Build conversation history
        history = context.get("history", [])
        
        try:
            messages = [
                {
                    "role": "system",
                    "content": """You are Scout, a friendly and helpful job search assistant for Offerloop.ai.
                    
Your capabilities:
- Parse job posting URLs to extract details
- Find job listings based on descriptions
- Help users choose the right search terms
- Answer questions about companies, roles, and interviews

You help users fill in the Professional Search form with:
- Job Title (required)
- Company (optional)
- Location (required)

Be concise, friendly, and action-oriented. Use emojis sparingly.
If the user seems stuck, suggest concrete next steps.
If you can extract job search fields from the conversation, mention them."""
                }
            ]
            
            # Add recent history
            for h in history[-6:]:  # Last 6 messages
                messages.append({"role": h["role"], "content": h["content"]})
            
            messages.append({"role": "user", "content": message})
            
            completion = await asyncio.wait_for(
                self._openai.chat.completions.create(
                    model=self.DEFAULT_MODEL,
                    messages=messages,
                    temperature=0.7,
                    max_tokens=400,
                ),
                timeout=15.0  # Increased from 8s to handle slower API responses
            )
            
            response_text = completion.choices[0].message.content
            
            # Update history
            new_history = history + [
                {"role": "user", "content": message},
                {"role": "assistant", "content": response_text},
            ]
            
            return ScoutResponse(
                status="ok",
                message=response_text,
                context=self._update_context(context, history=new_history[-10:]),
            )
            
        except asyncio.TimeoutError:
            print("[Scout] Conversation timed out - providing fallback response")
            # Try to provide a helpful response even on timeout
            message_lower = message.lower()
            if any(word in message_lower for word in ['internship', 'internships', 'job', 'jobs', 'position', 'positions']):
                return ScoutResponse(
                    status="ok",
                    message="I can help you find job opportunities! Try one of these:\n\n"
                            "ðŸ” **Search for jobs** - e.g., 'software engineering internships in Los Angeles'\n"
                            "ðŸ”— **Paste a job URL** - I'll extract the details and help you network\n"
                            "â“ **Ask about a role** - e.g., 'What skills do I need for data analyst roles?'\n\n"
                            "What would you like to search for?",
                    context=context,
                )
            return ScoutResponse(
                status="ok",
                message="I'm here to help you find professionals to network with! You can:\n\n"
                        "ðŸ”— **Paste a job posting URL** - I'll extract the details\n"
                        "ðŸ” **Describe what you're looking for** - e.g., 'data analyst jobs in NYC'\n"
                        "â“ **Ask me anything** - about companies, roles, or interviews\n\n"
                        "What would you like to do?",
                context=context,
            )
        except Exception as e:
            print(f"[Scout] Conversation failed: {e}")
            print(f"[Scout] Traceback: {traceback.format_exc()}")
            return ScoutResponse(
                status="ok",
                message="I'm here to help you find professionals to network with! You can:\n\n"
                        "ðŸ”— **Paste a job posting URL** - I'll extract the details\n"
                        "ðŸ” **Describe what you're looking for** - e.g., 'data analyst jobs in NYC'\n"
                        "â“ **Ask me anything** - about companies, roles, or interviews\n\n"
                        "What would you like to do?",
                context=context,
            )
    
    # ========================================================================
    # HELPERS
    # ========================================================================
    
    def _simplify_job_title(self, job_title: str) -> str:
        """
        Simplify overly specific job titles to improve search results.
        Removes department names, team names, project names, and extra qualifiers while keeping core role.
        
        Examples:
        - "Consulting Services - Senior Consultant" -> "Senior Consultant"
        - "AI Research Scientist, Text Data Research - MSL FAIR" -> "AI Research Scientist"
        - "Software Engineer, Infrastructure Team" -> "Software Engineer"
        - "Product Manager - Growth" -> "Product Manager"
        """
        if not job_title:
            return job_title
        
        title = job_title.strip()
        original_title = title
        
        # Common job role keywords (the actual role, not department)
        role_keywords = [
            'engineer', 'manager', 'scientist', 'analyst', 'designer',
            'developer', 'director', 'lead', 'architect', 'specialist',
            'consultant', 'coordinator', 'assistant', 'intern', 'researcher',
            'executive', 'officer', 'president', 'vice president', 'vp',
            'associate', 'senior', 'junior', 'principal', 'staff'
        ]
        
        # Department/service name indicators (usually not the actual role)
        department_keywords = [
            'services', 'solutions', 'department', 'division', 'team', 'group',
            'consulting', 'advisory', 'practice', 'unit', 'organization'
        ]
        
        # If title has dash, intelligently choose which part is the actual role
        if ' - ' in title or ' â€“ ' in title or ' â€” ' in title:
            # Try different dash types
            for dash in [' - ', ' â€“ ', ' â€” ']:
                if dash in title:
                    parts = [p.strip() for p in title.split(dash)]
                    
                    # Score each part: higher score = more likely to be the actual role
                    best_part = None
                    best_score = -1
                    
                    for i, part in enumerate(parts):
                        score = 0
                        part_lower = part.lower()
                        
                        # Points for having role keywords
                        for keyword in role_keywords:
                            if keyword in part_lower:
                                score += 2
                        
                        # Negative points for department keywords (unless it's clearly a role)
                        for dept_word in department_keywords:
                            if dept_word in part_lower:
                                # Only penalize if it's the ONLY word or clearly a department
                                if len(part.split()) <= 2 and not any(rk in part_lower for rk in role_keywords):
                                    score -= 3
                        
                        # Prefer parts that have both a role keyword AND a level (senior, junior, etc.)
                        if any(level in part_lower for level in ['senior', 'junior', 'principal', 'lead', 'staff', 'associate']):
                            if any(rk in part_lower for rk in role_keywords):
                                score += 3
                        
                        # Prefer second part if first looks like a department
                        if i == 1 and len(parts) > 0:
                            first_lower = parts[0].lower()
                            if any(dept in first_lower for dept in department_keywords):
                                score += 2
                        
                        if score > best_score:
                            best_score = score
                            best_part = part
                    
                    # Use the best part if we found one with a positive score
                    if best_part and best_score > 0:
                        title = best_part
                    # Fallback: if first part looks like department, use second
                    elif len(parts) > 1:
                        first_lower = parts[0].lower()
                        second = parts[1]
                        if any(dept in first_lower for dept in department_keywords):
                            if any(rk in second.lower() for rk in role_keywords):
                                title = second
                    break
        
        # If title has comma, find the part with the most role keywords
        if ',' in title:
            parts = [p.strip() for p in title.split(',')]
            
            best_part = None
            best_score = -1
            
            for part in parts:
                score = sum(1 for keyword in role_keywords if keyword in part.lower())
                # Penalize if it looks like a department
                part_lower = part.lower()
                if any(dept in part_lower for dept in department_keywords):
                    if not any(rk in part_lower for rk in role_keywords):
                        score -= 2
                
                if score > best_score:
                    best_score = score
                    best_part = part
            
            if best_part and best_score > 0:
                title = best_part
            else:
                # Default to first part
                title = parts[0]
        
        # Remove parenthetical team/project names: "Title (Team Name)"
        if '(' in title and ')' in title:
            title = re.sub(r'\s*\([^)]+\)', '', title).strip()
        
        # Remove trailing department/team indicators
        title = re.sub(r'\s*[-â€“â€”]\s*[A-Z][^a-z]*$', '', title)  # Remove " - MSL FAIR" type patterns
        title = re.sub(r',\s*[A-Z][^,]+$', '', title)  # Remove ", Team Name" at end
        
        # Final cleanup - remove extra spaces
        title = ' '.join(title.split())
        
        # If we ended up with something too short or just a department name, keep original
        if len(title) < 3 or title.lower() in department_keywords:
            return original_title
        
        return title
    
    def _normalize_location(self, location: str) -> Optional[str]:
        """
        Normalize location strings to PDL-compatible format: "City, ST"
        
        Examples:
            "Los Angeles, California, USA" -> "Los Angeles, CA"
            "San Francisco Bay Area" -> "San Francisco, CA"
            "New York City" -> "New York, NY"
            "NYC" -> "New York, NY"
            "Remote" -> None (or handle specially)
        """
        if not location:
            return None
        
        location = location.strip()
        
        # Handle remote
        if location.lower() in ['remote', 'remote - us', 'remote, us', 'work from home']:
            return None  # PDL doesn't search remote well
        
        # State abbreviation mapping
        STATE_ABBREV = {
            'alabama': 'AL', 'alaska': 'AK', 'arizona': 'AZ', 'arkansas': 'AR',
            'california': 'CA', 'colorado': 'CO', 'connecticut': 'CT', 'delaware': 'DE',
            'florida': 'FL', 'georgia': 'GA', 'hawaii': 'HI', 'idaho': 'ID',
            'illinois': 'IL', 'indiana': 'IN', 'iowa': 'IA', 'kansas': 'KS',
            'kentucky': 'KY', 'louisiana': 'LA', 'maine': 'ME', 'maryland': 'MD',
            'massachusetts': 'MA', 'michigan': 'MI', 'minnesota': 'MN', 'mississippi': 'MS',
            'missouri': 'MO', 'montana': 'MT', 'nebraska': 'NE', 'nevada': 'NV',
            'new hampshire': 'NH', 'new jersey': 'NJ', 'new mexico': 'NM', 'new york': 'NY',
            'north carolina': 'NC', 'north dakota': 'ND', 'ohio': 'OH', 'oklahoma': 'OK',
            'oregon': 'OR', 'pennsylvania': 'PA', 'rhode island': 'RI', 'south carolina': 'SC',
            'south dakota': 'SD', 'tennessee': 'TN', 'texas': 'TX', 'utah': 'UT',
            'vermont': 'VT', 'virginia': 'VA', 'washington': 'WA', 'west virginia': 'WV',
            'wisconsin': 'WI', 'wyoming': 'WY', 'district of columbia': 'DC'
        }
        
        # Common city aliases
        CITY_ALIASES = {
            'nyc': 'New York, NY',
            'new york city': 'New York, NY',
            'la': 'Los Angeles, CA',
            'sf': 'San Francisco, CA',
            'san francisco bay area': 'San Francisco, CA',
            'bay area': 'San Francisco, CA',
            'silicon valley': 'San Jose, CA',
            'dc': 'Washington, DC',
            'washington dc': 'Washington, DC',
            'philly': 'Philadelphia, PA',
            'chi-town': 'Chicago, IL',
            'atl': 'Atlanta, GA',
            'boston metro': 'Boston, MA',
            'dallas-fort worth': 'Dallas, TX',
            'dfw': 'Dallas, TX',
            'denver metro': 'Denver, CO',
            'seattle metro': 'Seattle, WA',
            'greater los angeles': 'Los Angeles, CA',
            'greater new york': 'New York, NY',
            'socal': 'Los Angeles, CA',
            'norcal': 'San Francisco, CA',
        }
        
        # Check aliases first
        location_lower = location.lower().strip()
        if location_lower in CITY_ALIASES:
            return CITY_ALIASES[location_lower]
        
        # Remove common suffixes
        location = re.sub(r',?\s*(USA|US|United States|America)$', '', location, flags=re.IGNORECASE).strip()
        location = re.sub(r',?\s*(Metro|Area|Region|Metropolitan)$', '', location, flags=re.IGNORECASE).strip()
        
        # Try to parse "City, State" or "City, ST"
        parts = [p.strip() for p in location.split(',')]
        
        if len(parts) >= 2:
            city = parts[0].strip()
            state_part = parts[1].strip()
            
            # Check if state_part is full state name
            state_lower = state_part.lower()
            if state_lower in STATE_ABBREV:
                return f"{city}, {STATE_ABBREV[state_lower]}"
            
            # Check if it's already abbreviated (2 letters)
            if len(state_part) == 2 and state_part.upper() in STATE_ABBREV.values():
                return f"{city}, {state_part.upper()}"
            
            # If 3+ parts, might be "City, State, Country" - take first two
            return f"{city}, {state_part}"
        
        # Single part - might be just a city, try to infer
        MAJOR_CITIES = {
            'new york': 'New York, NY',
            'los angeles': 'Los Angeles, CA',
            'chicago': 'Chicago, IL',
            'houston': 'Houston, TX',
            'phoenix': 'Phoenix, AZ',
            'philadelphia': 'Philadelphia, PA',
            'san antonio': 'San Antonio, TX',
            'san diego': 'San Diego, CA',
            'dallas': 'Dallas, TX',
            'san jose': 'San Jose, CA',
            'austin': 'Austin, TX',
            'jacksonville': 'Jacksonville, FL',
            'fort worth': 'Fort Worth, TX',
            'columbus': 'Columbus, OH',
            'charlotte': 'Charlotte, NC',
            'san francisco': 'San Francisco, CA',
            'indianapolis': 'Indianapolis, IN',
            'seattle': 'Seattle, WA',
            'denver': 'Denver, CO',
            'boston': 'Boston, MA',
            'nashville': 'Nashville, TN',
            'detroit': 'Detroit, MI',
            'portland': 'Portland, OR',  # Defaults to OR
            'miami': 'Miami, FL',
            'atlanta': 'Atlanta, GA',
        }
        
        if location_lower in MAJOR_CITIES:
            return MAJOR_CITIES[location_lower]
        
        # Return as-is if we can't normalize
        return location
    
    def _normalize_company(self, company: str) -> Optional[str]:
        """
        Normalize company names to common/searchable forms.
        
        Examples:
            "The Regents of the University of California on behalf of their Los Angeles Campus" -> "UCLA"
            "Meta Platforms, Inc." -> "Meta"
            "Alphabet Inc." -> "Google"
            "Amazon.com, Inc." -> "Amazon"
        """
        if not company:
            return None
        
        company = company.strip()
        original = company
        
        # University patterns - these are verbose legal names
        UNIVERSITY_MAPPINGS = {
            r'regents?\s+of\s+(the\s+)?university\s+of\s+california.*los\s+angeles': 'UCLA',
            r'regents?\s+of\s+(the\s+)?university\s+of\s+california.*berkeley': 'UC Berkeley',
            r'regents?\s+of\s+(the\s+)?university\s+of\s+california.*san\s+diego': 'UC San Diego',
            r'regents?\s+of\s+(the\s+)?university\s+of\s+california.*san\s+francisco': 'UCSF',
            r'regents?\s+of\s+(the\s+)?university\s+of\s+california.*irvine': 'UC Irvine',
            r'regents?\s+of\s+(the\s+)?university\s+of\s+california.*davis': 'UC Davis',
            r'regents?\s+of\s+(the\s+)?university\s+of\s+california.*santa\s+barbara': 'UC Santa Barbara',
            r'regents?\s+of\s+(the\s+)?university\s+of\s+california.*santa\s+cruz': 'UC Santa Cruz',
            r'regents?\s+of\s+(the\s+)?university\s+of\s+california.*riverside': 'UC Riverside',
            r'regents?\s+of\s+(the\s+)?university\s+of\s+california.*merced': 'UC Merced',
            r'regents?\s+of\s+(the\s+)?university\s+of\s+california': 'University of California',
            r'trustees?\s+of\s+(the\s+)?university\s+of\s+pennsylvania': 'University of Pennsylvania',
            r'president\s+and\s+fellows\s+of\s+harvard\s+college': 'Harvard University',
            r'leland\s+stanford\s+junior\s+university': 'Stanford University',
            r'massachusetts\s+institute\s+of\s+technology': 'MIT',
        }
        
        company_lower = company.lower()
        for pattern, replacement in UNIVERSITY_MAPPINGS.items():
            if re.search(pattern, company_lower):
                return replacement
        
        # Common company aliases/simplifications
        COMPANY_SIMPLIFY = {
            # Tech giants
            r'^meta\s+platforms?,?\s*(inc\.?)?$': 'Meta',
            r'^alphabet,?\s*(inc\.?)?$': 'Google',
            r'^amazon\.?com,?\s*(inc\.?)?$': 'Amazon',
            r'^apple,?\s*(inc\.?)?$': 'Apple',
            r'^microsoft\s*(corporation|corp\.?)?$': 'Microsoft',
            r'^netflix,?\s*(inc\.?)?$': 'Netflix',
            r'^nvidia\s*(corporation|corp\.?)?$': 'NVIDIA',
            r'^salesforce,?\s*(inc\.?)?$': 'Salesforce',
            r'^adobe,?\s*(inc\.?|systems)?$': 'Adobe',
            r'^oracle\s*(corporation|corp\.?)?$': 'Oracle',
            r'^international\s+business\s+machines\s*(corporation|corp\.?)?$': 'IBM',
            r'^ibm\s*(corporation|corp\.?)?$': 'IBM',
            
            # Finance
            r'^jpmorgan\s+chase\s*(&\s*co\.?)?': 'JPMorgan Chase',
            r'^goldman\s+sachs\s*(group|&\s*co\.?)?': 'Goldman Sachs',
            r'^morgan\s+stanley\s*(&\s*co\.?)?': 'Morgan Stanley',
            r'^bank\s+of\s+america\s*(corporation|corp\.?)?': 'Bank of America',
            r'^wells\s+fargo\s*(&\s*company)?': 'Wells Fargo',
            r'^citigroup,?\s*(inc\.?)?': 'Citigroup',
            r'^blackrock,?\s*(inc\.?)?': 'BlackRock',
            
            # Consulting
            r'^mckinsey\s*(&|and)?\s*(company|co\.?)?': 'McKinsey',
            r'^boston\s+consulting\s+group': 'BCG',
            r'^bain\s*(&|and)?\s*(company|co\.?)?': 'Bain',
            r'^deloitte\s*(touche\s+tohmatsu)?.*': 'Deloitte',
            r'^pricewaterhousecoopers.*': 'PwC',
            r'^pwc.*': 'PwC',
            r'^ernst\s*(&|and)?\s*young.*': 'EY',
            r'^kpmg.*': 'KPMG',
            r'^accenture,?\s*(plc)?': 'Accenture',
            
            # Government
            r'^county\s+of\s+(.+)$': r'\1 County',
            r'^city\s+of\s+(.+)$': r'\1',
            r'^state\s+of\s+(.+)$': r'\1',
        }
        
        for pattern, replacement in COMPANY_SIMPLIFY.items():
            match = re.match(pattern, company_lower)
            if match:
                # Handle backreferences in replacement
                if r'\1' in replacement:
                    return re.sub(pattern, replacement, company, flags=re.IGNORECASE).strip().title()
                return replacement
        
        # Generic cleanup
        # Remove legal suffixes
        company = re.sub(r',?\s*(Inc\.?|LLC|Ltd\.?|Corp\.?|Corporation|Company|Co\.?|PLC|LP|LLP)$', '', company, flags=re.IGNORECASE).strip()
        
        # Remove "The" prefix if followed by more words
        company = re.sub(r'^The\s+(?=\w+\s+)', '', company).strip()
        
        # If still very long (>50 chars), it's probably a legal name we didn't catch
        if len(company) > 50:
            # Try to extract the meaningful part
            # Often format is "Department - Organization" or "Organization - Department"
            if ' - ' in company:
                parts = company.split(' - ')
                # Take the shorter, more meaningful part
                company = min(parts, key=len).strip()
            elif ' on behalf of ' in company.lower():
                # Take part after "on behalf of"
                match = re.search(r'on behalf of\s+(.+)', company, re.IGNORECASE)
                if match:
                    company = match.group(1).strip()
        
        return company if company else original
    
    def _update_context(self, context: Dict[str, Any], **kwargs) -> Dict[str, Any]:
        """Update context with new information."""
        updated = dict(context)
        
        for key, value in kwargs.items():
            if value is not None:
                if key == "fields" and isinstance(value, SearchFields):
                    updated["last_fields"] = value.to_dict()
                elif key == "history":
                    updated["history"] = value
                else:
                    updated[key] = value
        
        # Track recent topics
        topics = updated.get("recent_topics", [])
        if kwargs.get("topic"):
            topics.append(kwargs["topic"])
            updated["recent_topics"] = topics[-5:]  # Keep last 5
        
        return updated
    
    # ========================================================================
    # FIRM SEARCH ASSISTANT
    # ========================================================================
    
    async def handle_firm_assist(
        self,
        *,
        message: str,
        firm_context: Dict[str, Any],
        user_resume: Optional[Dict[str, Any]] = None,
        fit_context: Optional[Dict[str, Any]] = None,
        conversation_history: Optional[List[Dict[str, str]]] = None,
    ) -> Dict[str, Any]:
        """
        Handle firm search assistant requests.
        Scout helps users find and research companies.
        """
        if not message.strip():
            # Check if user has resume - if yes, suggest generating a query
            if user_resume:
                return {
                    "status": "ok",
                    "message": "I can help you find the right firms! I can:\n\n"
                              "â€¢ **Generate a search query** based on your resume\n"
                              "â€¢ Refine your search\n"
                              "â€¢ Recommend firms based on your background\n"
                              "â€¢ Research a specific firm\n"
                              "â€¢ Suggest next steps\n\n"
                              "Want me to analyze your resume and suggest what to search for?",
                    "action_type": "general",
                }
            else:
                return {
                    "status": "ok",
                    "message": "I can help you find the right firms! You can ask me to:\n\n"
                              "â€¢ Refine your search\n"
                              "â€¢ Recommend firms based on your background\n"
                              "â€¢ Research a specific firm\n"
                              "â€¢ Suggest next steps\n\n"
                              "What would you like help with?",
                    "action_type": "general",
                }
        
        # Classify the request type
        action_type = await self._classify_firm_request(message)
        
        # Route to appropriate handler
        if action_type == "generate_query":
            return await self._handle_generate_firm_query(
                message, firm_context, user_resume
            )
        elif action_type == "refine_query":
            return await self._handle_refine_firm_query(
                message, firm_context, user_resume
            )
        elif action_type == "recommend_firms":
            return await self._handle_firm_recommendations(
                message, firm_context, user_resume, fit_context
            )
        elif action_type == "research_firm":
            return await self._handle_firm_research(
                message, firm_context
            )
        elif action_type == "next_steps":
            return await self._handle_firm_next_steps(
                message, firm_context, user_resume
            )
        else:
            return await self._handle_general_firm_help(
                message, firm_context, user_resume, fit_context, conversation_history
            )
    
    async def _classify_firm_request(self, message: str) -> str:
        """Classify what type of firm search help the user needs."""
        message_lower = message.lower()
        
        # Generate search query from resume
        if any(phrase in message_lower for phrase in [
            'help me find', 'find firms', 'suggest a search', 'what should i search',
            'generate a search', 'create a search', 'build a search', 'recommend a search',
            'according to my background', 'based on my resume', 'from my resume',
            'look at my resume', 'analyze my resume', 'using my background'
        ]):
            return "generate_query"
        
        # Query refinement
        if any(phrase in message_lower for phrase in [
            'refine', 'narrow', 'filter', 'smaller', 'larger', 'more',
            'less', 'different', 'add', 'remove', 'focus', 'only',
            'show me', 'find me', 'search for', 'change'
        ]):
            return "refine_query"
        
        # Firm recommendations based on background
        if any(phrase in message_lower for phrase in [
            'fit my background', 'fit me', 'match my', 'good for me',
            'recommend', 'suggestion', 'which firm', 'best for me',
            'based on my', 'my resume', 'my experience'
        ]):
            return "recommend_firms"
        
        # Research specific firm
        if any(phrase in message_lower for phrase in [
            'tell me about', 'what is', 'research', 'learn about',
            'info on', 'information about', 'culture', 'interview',
            'what do they', 'how is', 'news about'
        ]):
            return "research_firm"
        
        # Next steps
        if any(phrase in message_lower for phrase in [
            'next step', 'what now', 'what should i', 'find contacts',
            'reach out', 'how do i', 'apply', 'get started'
        ]):
            return "next_steps"
        
        return "general"
    
    async def _handle_generate_firm_query(
        self,
        message: str,
        firm_context: Dict[str, Any],
        user_resume: Optional[Dict[str, Any]],
    ) -> Dict[str, Any]:
        """Generate a firm search query based on user's resume/background."""
        
        if not user_resume:
            return {
                "status": "ok",
                "message": "I'd need to see your resume to generate a personalized search query. "
                          "Make sure your resume is uploaded in Account Settings.\n\n"
                          "Once uploaded, I can analyze your background and suggest the best firms to target!",
                "action_type": "generate_query",
            }
        
        prompt = f"""Analyze this user's resume and generate a relevant FIRM/COMPANY search query for them.

USER'S RESUME:
{json.dumps(user_resume, indent=2)[:3000]}

USER'S REQUEST:
{message}

CRITICAL: This is a FIRM SEARCH, not a job search. Generate a query to find COMPANIES/FIRMS, not job positions.

TASK:
Generate a natural language firm search query that would help this user find relevant COMPANIES to target.

IMPORTANT REQUIREMENTS:
1. Industry must be one of these exact values:
   - "investment banking"
   - "real estate private equity"
   - "venture capital"
   - "private equity"
   - "consulting"
   - "software engineering"
   - "product management"
   - "hedge fund"
   - "asset management"
   - "accounting"
   
   Map similar terms:
   - "data science" â†’ "software engineering" (data science companies are software/tech companies)
   - "VC" â†’ "venture capital"
   - "PE" â†’ "private equity"
   - "IB" â†’ "investment banking"
   - "MBB" â†’ "consulting"
   - "tech" â†’ "software engineering"
   - "finance" â†’ "investment banking" or "asset management" depending on context

2. Location must be included (city, state, or region). If not in resume, use a major city relevant to their field.

3. Query format should be about COMPANIES/FIRMS, not job positions:
   âœ… CORRECT: "Mid-sized investment banks in New York focused on healthcare M&A"
   âœ… CORRECT: "Software engineering companies in Los Angeles focused on data science"
   âœ… CORRECT: "Boutique consulting firms in San Francisco"
   âœ… CORRECT: "Venture capital firms in Boston focused on biotech"
   âŒ WRONG: "Entry-level data science positions in Los Angeles" (this is a job search, not firm search)
   âŒ WRONG: "Data analyst jobs in NYC" (this is a job search, not firm search)

4. Focus on COMPANY characteristics:
   - Company size: "boutique", "mid-sized", "large"
   - Company type: "firms", "companies", "organizations"
   - Industry focus areas (optional): "focused on X", "specializing in Y"

Consider:
- Their industry/field of work (map to one of the exact industry values above)
- Their experience level (intern, entry, mid, senior) - use size qualifiers like "boutique" for smaller firms, "mid-sized", "large"
- Their location preferences (if apparent from resume, otherwise use a major hub for their industry)
- Their skills and expertise areas (can be mentioned as company focus areas, not job requirements)
- Their career trajectory

Return JSON:
{{
    "search_query": "the natural language search query to find COMPANIES/FIRMS (MUST include industry and location, focus on companies not jobs)",
    "explanation": "brief explanation of why this search is relevant to their background (2-3 sentences)",
    "key_factors": ["factor 1", "factor 2", "factor 3"]
}}
"""

        try:
            completion = await asyncio.wait_for(
                self._openai.chat.completions.create(
                    model=self.DEFAULT_MODEL,
                    messages=[
                        {"role": "system", "content": "You analyze resumes and generate relevant firm search queries. Be specific and actionable."},
                        {"role": "user", "content": prompt},
                    ],
                    temperature=0.7,
                    max_tokens=400,
                    response_format={"type": "json_object"},
                ),
                timeout=12.0
            )
            
            result = json.loads(completion.choices[0].message.content)
            
            # Format response
            response_parts = [
                "ðŸŽ¯ **Based on your background, here's a search query I'd recommend:**\n",
                f"**\"{result['search_query']}\"**\n",
                f"\n{result.get('explanation', '')}\n",
            ]
            
            if result.get('key_factors'):
                response_parts.append("\n**Key factors I considered:**")
                for factor in result['key_factors'][:3]:
                    response_parts.append(f"â€¢ {factor}")
            
            response_parts.append("\n\nClick the button below to use this search!")
            
            return {
                "status": "ok",
                "message": "\n".join(response_parts),
                "suggestions": {
                    "refined_query": result["search_query"],
                },
                "action_type": "generate_query",
            }
            
        except Exception as e:
            print(f"[Scout] Generate firm query failed: {e}")
            return {
                "status": "error",
                "message": "I had trouble analyzing your resume. Could you try asking me to recommend firms instead?",
                "action_type": "generate_query",
            }
    
    async def _handle_refine_firm_query(
        self,
        message: str,
        firm_context: Dict[str, Any],
        user_resume: Optional[Dict[str, Any]],
    ) -> Dict[str, Any]:
        """Help user refine their firm search query."""
        
        current_query = firm_context.get("current_query", "")
        current_results = firm_context.get("current_results", [])
        parsed_filters = firm_context.get("parsed_filters", {})
        
        prompt = f"""Help refine a firm search query based on the user's request.

CURRENT QUERY:
{current_query}

CURRENT FILTERS PARSED:
{json.dumps(parsed_filters, indent=2)}

CURRENT RESULTS ({len(current_results)} firms):
{chr(10).join(f"- {f.get('name', 'Unknown')} ({f.get('industry', 'Unknown')})" for f in current_results[:10])}

USER'S REQUEST:
{message}

TASK:
Generate a refined search query that addresses the user's request.

Guidelines:
- Keep the natural language format (e.g., "Boutique investment banks in NYC...")
- Be specific but not overly restrictive
- If user wants "smaller" firms, add size qualifiers like "boutique" or "with under 500 employees"
- If user wants different location, update the location
- If user wants different industry focus, update that

Return JSON:
{{
    "refined_query": "the new search query to use",
    "explanation": "brief explanation of what changed (1 sentence)",
    "filters_changed": ["list", "of", "changed", "filters"]
}}
"""

        try:
            completion = await asyncio.wait_for(
                self._openai.chat.completions.create(
                    model=self.DEFAULT_MODEL,
                    messages=[
                        {"role": "system", "content": "You help refine company search queries. Be specific and actionable."},
                        {"role": "user", "content": prompt},
                    ],
                    temperature=0.7,
                    max_tokens=300,
                    response_format={"type": "json_object"},
                ),
                timeout=10.0
            )
            
            result = json.loads(completion.choices[0].message.content)
            
            return {
                "status": "ok",
                "message": f"Here's a refined search:\n\n**\"{result['refined_query']}\"**\n\n{result.get('explanation', '')}",
                "suggestions": {
                    "refined_query": result["refined_query"],
                },
                "action_type": "refine_query",
            }
            
        except Exception as e:
            print(f"[Scout] Refine firm query failed: {e}")
            return {
                "status": "error",
                "message": "I had trouble refining that. Could you be more specific about what you'd like to change?",
                "action_type": "refine_query",
            }
    
    async def _handle_firm_recommendations(
        self,
        message: str,
        firm_context: Dict[str, Any],
        user_resume: Optional[Dict[str, Any]],
        fit_context: Optional[Dict[str, Any]],
    ) -> Dict[str, Any]:
        """Recommend firms based on user's background."""
        
        current_results = firm_context.get("current_results", [])
        
        if not user_resume:
            return {
                "status": "ok",
                "message": "I'd need to see your resume to give personalized recommendations. "
                          "Make sure your resume is uploaded in Account Settings.\n\n"
                          "In the meantime, I can tell you about any of the firms in your resultsâ€”just ask!",
                "action_type": "recommend_firms",
            }
        
        if not current_results:
            return {
                "status": "ok",
                "message": "Run a search first, then I can tell you which firms are the best fit for your background!",
                "action_type": "recommend_firms",
            }
        
        prompt = f"""Analyze which firms from the search results best match this user's background.

USER'S RESUME:
{json.dumps(user_resume, indent=2)[:3000]}

{"TARGET ROLE (from fit analysis):" if fit_context else ""}
{f"{fit_context.get('job_title', '')} at {fit_context.get('company', '')}" if fit_context else ""}

SEARCH RESULTS ({len(current_results)} firms):
{json.dumps([{
    'name': f.get('name'),
    'industry': f.get('industry'),
    'size': f.get('size'),
    'location': f.get('location', {}).get('display') if isinstance(f.get('location'), dict) else f.get('location'),
    'description': f.get('description', '')[:200]
} for f in current_results[:15]], indent=2)}

TASK:
Identify the top 3 firms that best match this user's background. For each, explain WHY it's a good fit.

Consider:
- School/alumni networks
- Industry experience alignment
- Skills match
- Location preferences (if apparent from resume)
- Career trajectory fit

Return JSON:
{{
    "recommendations": [
        {{
            "firm_name": "Firm Name",
            "fit_reason": "Specific reason this firm fits their background",
            "talking_point": "Something they could mention when reaching out"
        }}
    ],
    "overall_insight": "One sentence about their search/fit overall"
}}
"""

        try:
            completion = await asyncio.wait_for(
                self._openai.chat.completions.create(
                    model=self.DEFAULT_MODEL,
                    messages=[
                        {"role": "system", "content": "You're a career advisor matching candidates to companies. Be specific about why each firm is a good fit."},
                        {"role": "user", "content": prompt},
                    ],
                    temperature=0.7,
                    max_tokens=600,
                    response_format={"type": "json_object"},
                ),
                timeout=12.0
            )
            
            result = json.loads(completion.choices[0].message.content)
            recommendations = result.get("recommendations", [])
            
            # Format response
            response_parts = ["ðŸŽ¯ **Based on your background, here are my top picks:**\n"]
            
            for i, rec in enumerate(recommendations[:3], 1):
                response_parts.append(f"**{i}. {rec.get('firm_name', 'Unknown')}**")
                response_parts.append(f"   {rec.get('fit_reason', '')}")
                if rec.get('talking_point'):
                    response_parts.append(f"   ðŸ’¬ *Talking point: {rec.get('talking_point')}*")
                response_parts.append("")
            
            if result.get("overall_insight"):
                response_parts.append(f"ðŸ’¡ {result['overall_insight']}")
            
            response_parts.append("\nWant me to find contacts at any of these?")
            
            return {
                "status": "ok",
                "message": "\n".join(response_parts),
                "suggestions": {
                    "recommended_firms": [r.get("firm_name") for r in recommendations],
                },
                "action_type": "recommend_firms",
            }
            
        except Exception as e:
            print(f"[Scout] Firm recommendations failed: {e}")
            return {
                "status": "error",
                "message": "I had trouble analyzing the results. Try asking about a specific firm instead!",
                "action_type": "recommend_firms",
            }
    
    async def _handle_firm_research(
        self,
        message: str,
        firm_context: Dict[str, Any],
    ) -> Dict[str, Any]:
        """Research a specific firm for the user."""
        
        current_results = firm_context.get("current_results", [])
        
        # Try to identify which firm they're asking about
        firm_name = None
        message_lower = message.lower()
        
        # Check if they mentioned a firm from results
        for firm in current_results:
            name = firm.get("name", "").lower()
            if name and name in message_lower:
                firm_name = firm.get("name")
                break
        
        # Common firm name patterns
        if not firm_name:
            # Extract firm name from phrases like "tell me about Goldman" or "what is McKinsey like"
            patterns = [
                r'(?:tell me about|about|what is|how is|research|info on)\s+([A-Z][A-Za-z\s&]+?)(?:\s+like|\s+as|\?|$|\.)',
                r"([A-Z][A-Za-z\s&]+?)(?:'s)?\s+(?:culture|interview|hiring|team)",
            ]
            for pattern in patterns:
                match = re.search(pattern, message, re.IGNORECASE)
                if match:
                    firm_name = match.group(1).strip()
                    break
        
        if not firm_name:
            return {
                "status": "ok",
                "message": "Which firm would you like me to research? You can ask things like:\n\n"
                          "â€¢ \"Tell me about Goldman Sachs\"\n"
                          "â€¢ \"What's the culture like at McKinsey?\"\n"
                          "â€¢ \"What does Bain look for in candidates?\"",
                "action_type": "research_firm",
            }
        
        prompt = f"""Provide helpful information about {firm_name} for someone exploring career opportunities there.

FIRM: {firm_name}

Provide a helpful overview covering:
1. What they do / what they're known for
2. Culture and work environment (what you'd experience)
3. What they typically look for in candidates
4. Any recent news or notable things
5. Tips for getting in / standing out

Keep it practical and actionable. Be honest about both positives and challenges.
Keep total response under 250 words.

Return JSON:
{{
    "firm_name": "{firm_name}",
    "overview": "1-2 sentence summary of what they do",
    "culture": "What the work environment is like",
    "what_they_look_for": "Key qualities/backgrounds they value",
    "tips": ["tip 1", "tip 2"],
    "recent_news": "Any notable recent developments (or null if unknown)"
}}
"""

        try:
            completion = await asyncio.wait_for(
                self._openai.chat.completions.create(
                    model=self.DEFAULT_MODEL,
                    messages=[
                        {"role": "system", "content": "You provide helpful, accurate information about companies for job seekers. Be balanced and practical."},
                        {"role": "user", "content": prompt},
                    ],
                    temperature=0.7,
                    max_tokens=500,
                    response_format={"type": "json_object"},
                ),
                timeout=12.0
            )
            
            result = json.loads(completion.choices[0].message.content)
            
            # Format response
            response_parts = [f"**{result.get('firm_name', firm_name)}**\n"]
            response_parts.append(f"{result.get('overview', '')}\n")
            
            if result.get('culture'):
                response_parts.append(f"**Culture:** {result['culture']}\n")
            
            if result.get('what_they_look_for'):
                response_parts.append(f"**What they look for:** {result['what_they_look_for']}\n")
            
            if result.get('tips'):
                response_parts.append("**Tips to stand out:**")
                for tip in result['tips'][:3]:
                    response_parts.append(f"â€¢ {tip}")
                response_parts.append("")
            
            if result.get('recent_news'):
                response_parts.append(f"ðŸ“° *{result['recent_news']}*\n")
            
            response_parts.append("Want me to find contacts here, or research another firm?")
            
            return {
                "status": "ok",
                "message": "\n".join(response_parts),
                "suggestions": {
                    "firm_insights": result,
                },
                "action_type": "research_firm",
            }
            
        except Exception as e:
            print(f"[Scout] Firm research failed: {e}")
            return {
                "status": "error",
                "message": f"I had trouble researching {firm_name}. Try asking a more specific question about them!",
                "action_type": "research_firm",
            }
    
    async def _handle_firm_next_steps(
        self,
        message: str,
        firm_context: Dict[str, Any],
        user_resume: Optional[Dict[str, Any]],
    ) -> Dict[str, Any]:
        """Suggest next steps after finding firms."""
        
        current_results = firm_context.get("current_results", [])
        
        if not current_results:
            return {
                "status": "ok",
                "message": "First, let's find some firms! Describe what you're looking for:\n\n"
                          "â€¢ Industry (e.g., investment banking, consulting, tech)\n"
                          "â€¢ Location (e.g., New York, San Francisco)\n"
                          "â€¢ Size (e.g., boutique, mid-sized, large)\n"
                          "â€¢ Focus area (e.g., healthcare, tech M&A)",
                "action_type": "next_steps",
            }
        
        # Extract firm names for suggestions
        firm_names = [f.get("name", "Unknown") for f in current_results[:5]]
        
        response = f"""Great, you have {len(current_results)} firms saved! Here are your next steps:

**1. Find Contacts**
Click "View Contacts" on any firm to find people to reach out to. I'd prioritize:
â€¢ {firm_names[0] if firm_names else 'Your top choice firm'}
â€¢ Alumni from your school at any of these firms

**2. Research Before Reaching Out**
Ask me about any firm's culture, interview process, or what they look for.

**3. Prep Your Outreach**
Once you find contacts, use Coffee Chat Prep to prepare for conversations.

**Quick actions:**
â€¢ "Find contacts at {firm_names[0] if firm_names else 'Goldman Sachs'}"
â€¢ "Which firms fit my background?"
â€¢ "Tell me about {firm_names[0] if firm_names else 'the top firm'}'s interview process"

What would you like to do?"""

        return {
            "status": "ok",
            "message": response,
            "suggestions": {
                "next_steps": [
                    "Find contacts at top firms",
                    "Research firm culture",
                    "Prep for outreach"
                ],
            },
            "action_type": "next_steps",
        }
    
    async def _handle_general_firm_help(
        self,
        message: str,
        firm_context: Dict[str, Any],
        user_resume: Optional[Dict[str, Any]],
        fit_context: Optional[Dict[str, Any]],
        conversation_history: Optional[List[Dict[str, str]]],
    ) -> Dict[str, Any]:
        """Handle general firm search questions."""
        
        current_results = firm_context.get("current_results", [])
        current_query = firm_context.get("current_query", "")
        
        # Build conversation context
        history_text = ""
        if conversation_history:
            for msg in conversation_history[-6:]:
                role = "You" if msg.get("role") == "user" else "Scout"
                history_text += f"{role}: {msg.get('content', '')}\n"
        
        prompt = f"""You're Scout, an assistant helping with firm/company search.

CONTEXT:
- Current search query: {current_query or 'No search yet'}
- Results: {len(current_results)} firms found
- Top firms: {', '.join(f.get('name', 'Unknown') for f in current_results[:5]) if current_results else 'None yet'}

{"USER'S BACKGROUND:" if user_resume else ""}
{f"School: {user_resume.get('education', [{}])[0].get('school', 'Unknown')}" if user_resume and user_resume.get('education') else ""}

{"RECENT CONVERSATION:" if history_text else ""}
{history_text}

USER'S MESSAGE:
{message}

Respond helpfully and concisely. Guide them toward:
- Refining their search
- Getting recommendations based on their background
- Researching specific firms
- Finding contacts at firms they like

Keep responses under 100 words unless detail is needed.
"""

        try:
            completion = await asyncio.wait_for(
                self._openai.chat.completions.create(
                    model=self.DEFAULT_MODEL,
                    messages=[
                        {"role": "system", "content": "You're Scout, a friendly assistant helping with company research. Be concise, helpful, and proactive."},
                        {"role": "user", "content": prompt},
                    ],
                    temperature=0.7,
                    max_tokens=300,
                ),
                timeout=10.0
            )
            
            return {
                "status": "ok",
                "message": completion.choices[0].message.content.strip(),
                "action_type": "general",
            }
            
        except Exception as e:
            print(f"[Scout] General firm help failed: {e}")
            return {
                "status": "ok",
                "message": "I'm here to help with your firm search! I can:\n\n"
                          "â€¢ Refine your search query\n"
                          "â€¢ Recommend firms based on your background\n"
                          "â€¢ Research specific companies\n"
                          "â€¢ Suggest next steps\n\n"
                          "What would you like help with?",
                "action_type": "general",
            }


# ============================================================================
# SINGLETON INSTANCE
# ============================================================================

scout_service = ScoutService()
